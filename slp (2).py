# -*- coding: utf-8 -*-
"""SLP.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1Ii0LSUDCFFtL5ICnsrpy2ycGx5PTpSRr
"""

import tensorflow as tf
import numpy as np
import random
from datasets import load_dataset
import nltk
from nltk.translate.bleu_score import sentence_bleu

!pip install datasets

from datasets import load_dataset

# Try loading a different dataset (e.g., opus_books)
try:
    dataset = load_dataset("opus_books", "en-fr", split="train[:5000]")
except Exception as e:
    print("Error loading dataset:", e)

# Extract source (English) and target (French) sentences
input_texts = [example["translation"]["en"] for example in dataset]
target_texts = [example["translation"]["fr"] for example in dataset]

print(f"Loaded {len(input_texts)} sentence pairs.")

max_vocab_size = 10000
max_length = 40  # maximum sequence length for inputs

# Create TextVectorization layers for both source and target languages.
input_vectorizer = tf.keras.layers.TextVectorization(
    max_tokens=max_vocab_size,
    output_mode="int",
    output_sequence_length=max_length
)
# For the target language, we add one extra token for shifting (start/end token)
target_vectorizer = tf.keras.layers.TextVectorization(
    max_tokens=max_vocab_size,
    output_mode="int",
    output_sequence_length=max_length + 1
)

# Fit the vectorizers on the raw text data.
input_vectorizer.adapt(input_texts)
target_vectorizer.adapt(target_texts)

# Convert texts to sequences (padded integers)
input_sequences = input_vectorizer(np.array(input_texts))
target_sequences = target_vectorizer(np.array(target_texts))

# Prepare sequences for the decoder.
# The decoder uses the target sequence offset by one time step:
# - The decoder input is the target sequence except for the last token.
# - The decoder target (labels) is the target sequence except for the first token.
decoder_input_sequences = target_sequences[:, :-1]
decoder_target_sequences = target_sequences[:, 1:]

# Create a tf.data.Dataset for training.
BATCH_SIZE = 64
BUFFER_SIZE = 2000

train_dataset = tf.data.Dataset.from_tensor_slices((
    {"encoder_input": input_sequences, "decoder_input": decoder_input_sequences},
    decoder_target_sequences
)).shuffle(BUFFER_SIZE).batch(BATCH_SIZE, drop_remainder=True)

# Determine vocabulary sizes (including special tokens)
vocab_inp_size = len(input_vectorizer.get_vocabulary())
vocab_tar_size = len(target_vectorizer.get_vocabulary())

print("Input vocabulary size:", vocab_inp_size)
print("Target vocabulary size:", vocab_tar_size)

# Encoder Model
class Encoder(tf.keras.Model):
    def __init__(self, vocab_size, embedding_dim, enc_units):
        super(Encoder, self).__init__()
        self.enc_units = enc_units
        self.embedding = tf.keras.layers.Embedding(vocab_size, embedding_dim)
        self.gru = tf.keras.layers.GRU(enc_units,
                                       return_sequences=True,
                                       return_state=True,
                                       recurrent_initializer='glorot_uniform')

    def call(self, x, hidden):
        x = self.embedding(x)
        output, state = self.gru(x, initial_state=hidden)
        return output, state

    def initialize_hidden_state(self, batch_size):
        return tf.zeros((batch_size, self.enc_units))

# Bahdanau Attention Mechanism
class BahdanauAttention(tf.keras.layers.Layer):
    def __init__(self, units):
        super(BahdanauAttention, self).__init__()
        self.W1 = tf.keras.layers.Dense(units)
        self.W2 = tf.keras.layers.Dense(units)
        self.V  = tf.keras.layers.Dense(1)

    def call(self, query, values):
        # query shape: (batch_size, hidden_size) --> (batch_size, 1, hidden_size)
        query_with_time_axis = tf.expand_dims(query, 1)
        # values shape: (batch_size, max_length, hidden_size)
        score = self.V(tf.nn.tanh(self.W1(query_with_time_axis) + self.W2(values)))
        # attention_weights shape: (batch_size, max_length, 1)
        attention_weights = tf.nn.softmax(score, axis=1)
        # context_vector shape: (batch_size, hidden_size)
        context_vector = attention_weights * values
        context_vector = tf.reduce_sum(context_vector, axis=1)
        return context_vector, tf.squeeze(attention_weights, -1)

# Decoder Model
class Decoder(tf.keras.Model):
    def __init__(self, vocab_size, embedding_dim, dec_units):
        super(Decoder, self).__init__()
        self.dec_units = dec_units
        self.embedding = tf.keras.layers.Embedding(vocab_size, embedding_dim)
        self.gru = tf.keras.layers.GRU(dec_units,
                                       return_sequences=True,
                                       return_state=True,
                                       recurrent_initializer='glorot_uniform')
        self.fc = tf.keras.layers.Dense(vocab_size)
        # Attention layer
        self.attention = BahdanauAttention(dec_units)

    def call(self, x, hidden, enc_output):
        # Compute attention context vector using the encoder output and current hidden state.
        context_vector, attention_weights = self.attention(hidden, enc_output)

        # x shape: (batch_size, 1)
        x = self.embedding(x)  # now shape: (batch_size, 1, embedding_dim)
        # Concatenate the context vector with the embedded input.
        x = tf.concat([tf.expand_dims(context_vector, 1), x], axis=-1)

        # Pass through GRU
        output, state = self.gru(x)
        output = tf.reshape(output, (-1, output.shape[2]))  # flatten output for Dense layer

        x = self.fc(output)
        return x, state, attention_weights

# Hyperparameters for embedding and GRU units.
embedding_dim = 256
units = 512

# Instantiate encoder and decoder.
encoder = Encoder(vocab_inp_size, embedding_dim, units)
decoder = Decoder(vocab_tar_size, embedding_dim, units)

# 3. DEFINE THE LOSS FUNCTION AND OPTIMIZER
###############################################

optimizer = tf.keras.optimizers.Adam()

# Use sparse categorical crossentropy, ignoring the padded zeros.
loss_object = tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True, reduction='none')

def loss_function(real, pred):
    # Create a mask to ignore loss from padding tokens.
    mask = tf.math.logical_not(tf.math.equal(real, 0))
    loss_ = loss_object(real, pred)

    mask = tf.cast(mask, dtype=loss_.dtype)
    loss_ *= mask

    return tf.reduce_mean(loss_)

EPOCHS = 10
import time
@tf.function
def train_step(enc_inp, dec_inp, dec_target, hidden):
    loss = 0
    with tf.GradientTape() as tape:
        # Encode the input
        enc_output, enc_hidden = encoder(enc_inp, hidden)
        dec_hidden = enc_hidden

        # Teacher forcing: initialize decoder input with the first token for each sequence
        dec_input = tf.expand_dims(dec_inp[:, 0], 1)

        # Process each time step in the decoder sequence
        for t in range(1, dec_inp.shape[1]):
            predictions, dec_hidden, _ = decoder(dec_input, dec_hidden, enc_output)
            loss += loss_function(dec_target[:, t - 1], predictions)
            # Use teacher forcing: next decoder input is current target token
            dec_input = tf.expand_dims(dec_inp[:, t], 1)

    batch_loss = loss / int(dec_inp.shape[1] - 1)
    variables = encoder.trainable_variables + decoder.trainable_variables
    gradients = tape.gradient(loss, variables)
    optimizer.apply_gradients(zip(gradients, variables))
    return batch_loss

for epoch in range(EPOCHS):
    start = time.time()
    hidden = encoder.initialize_hidden_state(BATCH_SIZE)
    total_loss = 0

    for batch, (inp, targ) in enumerate(train_dataset):
        batch_loss = train_step(inp["encoder_input"], inp["decoder_input"], targ, hidden)
        total_loss += batch_loss
        if batch % 50 == 0:
            print(f'Epoch {epoch + 1} Batch {batch} Loss {batch_loss.numpy():.4f}')

    print(f'Epoch {epoch + 1} Loss {total_loss / (batch + 1):.4f}')
    print(f'Time taken for epoch {epoch + 1}: {time.time() - start:.2f} sec\n')

from nltk.translate.bleu_score import SmoothingFunction, sentence_bleu

def evaluate(sentence, encoder, decoder):
    # Convert input sentence to a tensor
    sentence = tf.convert_to_tensor([sentence])

    # Vectorize the input sentence and ensure it's cast to int32
    sentence_seq = input_vectorizer(sentence)
    sentence_seq = tf.cast(sentence_seq, tf.int32)  # Ensure input is integer

    # Initialize the encoder hidden state
    hidden = encoder.initialize_hidden_state(1)
    enc_out, enc_hidden = encoder(sentence_seq, hidden)

    dec_hidden = enc_hidden

    # Debugging: Print vocabulary to verify token existence
    vocab = target_vectorizer.get_vocabulary()
    print(f"Vocabulary: {vocab[:10]}... (showing first 10 words)")  # Debug print to check vocabulary

    # Ensure '<start>' exists, otherwise, use index 1 as default start token
    start_token = vocab.index('<start>') if '<start>' in vocab else 1
    dec_input = tf.expand_dims([start_token], 0)

    result = []
    for _ in range(max_length):
        predictions, dec_hidden, _ = decoder(dec_input, dec_hidden, enc_out)
        predicted_id = tf.argmax(predictions[0]).numpy()

        if predicted_id == 0:  # Assume 0 is the end token
            break
        result.append(vocab[predicted_id])
        dec_input = tf.expand_dims([predicted_id], 0)

    return ' '.join(result)
# Evaluate the model using BLEU score on the first 100 examples
bleu_scores = []
num_eval = 100
smoother = SmoothingFunction().method1  # Smoothing function for BLEU

for i in range(num_eval):
    reference = nltk.word_tokenize(target_texts[i].lower())
    prediction = nltk.word_tokenize(evaluate(input_texts[i], encoder, decoder).lower())

    # Debugging: Print tokens
    print(f"\nSource: {input_texts[i]}")
    print(f"Reference tokens: {reference}")
    print(f"Prediction tokens: {prediction}")

    # Calculate BLEU score with smoothing
    bleu = sentence_bleu([reference], prediction, smoothing_function=smoother)
    bleu_scores.append(bleu)

    print(f"BLEU score: {bleu:.4f}")

avg_bleu = np.mean(bleu_scores)
print(f"\nAverage BLEU score over {num_eval} examples: {avg_bleu:.4f}")

nltk.download('punkt_tab')

!pip install streamlit

!pip install streamlit pyngrok nltk

import nltk
nltk.download('punkt')

!pip install streamlit pyngrok

